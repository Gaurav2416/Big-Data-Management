{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f2758d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "708d2f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "58a082a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e86cfc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "numb_batch = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ae4468",
   "metadata": {},
   "source": [
    "#Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d9c14ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: mnist_data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "T = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "train_data = torchvision.datasets.MNIST('mnist_data', train=True, download=True, transform=T)\n",
    "val_data = torchvision.datasets.MNIST('mnist_data', train=False, download=True, transform=T)\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_data, batch_size = numb_batch)\n",
    "val_dl = torch.utils.data.DataLoader(val_data, batch_size = numb_batch)\n",
    "\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ff56e56d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f83b0c2ed00>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAN80lEQVR4nO3df6hcdXrH8c+ncf3DrBpTMYasNhuRWBWbLRqLSl2RrD9QNOqWDVgsBrN/GHChhEr6xyolEuqP0qAsuYu6sWyzLqgYZVkVo6ZFCF5j1JjU1YrdjV6SSozG+KtJnv5xT+Su3vnOzcyZOZP7vF9wmZnzzJnzcLife87Md879OiIEYPL7k6YbANAfhB1IgrADSRB2IAnCDiRxRD83ZpuP/oEeiwiPt7yrI7vtS22/aftt27d281oAesudjrPbniLpd5IWSNou6SVJiyJia2EdjuxAj/XiyD5f0tsR8U5EfCnpV5Ku6uL1APRQN2GfJekPYx5vr5b9EdtLbA/bHu5iWwC61M0HdOOdKnzjND0ihiQNSZzGA03q5si+XdJJYx5/R9L73bUDoFe6CftLkk61/V3bR0r6kaR19bQFoG4dn8ZHxD7bSyU9JWmKpAci4o3aOgNQq46H3jraGO/ZgZ7ryZdqABw+CDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUii4ymbcXiYMmVKsX7sscf2dPtLly5tWTvqqKOK686dO7dYv/nmm4v1u+66q2Vt0aJFxXU///zzYn3lypXF+u23316sN6GrsNt+V9IeSfsl7YuIs+toCkD96jiyXxQRH9TwOgB6iPfsQBLdhj0kPW37ZdtLxnuC7SW2h20Pd7ktAF3o9jT+/Ih43/YJkp6x/V8RsWHsEyJiSNKQJNmOLrcHoENdHdkj4v3qdqekxyTNr6MpAPXrOOy2p9o++uB9ST+QtKWuxgDUq5vT+BmSHrN98HX+PSJ+W0tXk8zJJ59crB955JHF+nnnnVesX3DBBS1r06ZNK6577bXXFutN2r59e7G+atWqYn3hwoUta3v27Cmu++qrrxbrL7zwQrE+iDoOe0S8I+kvauwFQA8x9AYkQdiBJAg7kARhB5Ig7EASjujfl9om6zfo5s2bV6yvX7++WO/1ZaaD6sCBA8X6jTfeWKx/8sknHW97ZGSkWP/www+L9TfffLPjbfdaRHi85RzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtlrMH369GJ948aNxfqcOXPqbKdW7XrfvXt3sX7RRRe1rH355ZfFdbN+/6BbjLMDyRF2IAnCDiRB2IEkCDuQBGEHkiDsQBJM2VyDXbt2FevLli0r1q+44opi/ZVXXinW2/1L5ZLNmzcX6wsWLCjW9+7dW6yfccYZLWu33HJLcV3UiyM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTB9ewD4JhjjinW200vvHr16pa1xYsXF9e9/vrri/W1a9cW6xg8HV/PbvsB2zttbxmzbLrtZ2y/Vd0eV2ezAOo3kdP4X0i69GvLbpX0bEScKunZ6jGAAdY27BGxQdLXvw96laQ11f01kq6uty0Adev0u/EzImJEkiJixPYJrZ5oe4mkJR1uB0BNen4hTEQMSRqS+IAOaFKnQ287bM+UpOp2Z30tAeiFTsO+TtIN1f0bJD1eTzsAeqXtabzttZK+L+l429sl/VTSSkm/tr1Y0u8l/bCXTU52H3/8cVfrf/TRRx2ve9NNNxXrDz/8cLHebo51DI62YY+IRS1KF9fcC4Ae4uuyQBKEHUiCsANJEHYgCcIOJMElrpPA1KlTW9aeeOKJ4roXXnhhsX7ZZZcV608//XSxjv5jymYgOcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9knulFNOKdY3bdpUrO/evbtYf+6554r14eHhlrX77ruvuG4/fzcnE8bZgeQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtmTW7hwYbH+4IMPFutHH310x9tevnx5sf7QQw8V6yMjIx1vezJjnB1IjrADSRB2IAnCDiRB2IEkCDuQBGEHkmCcHUVnnnlmsX7PPfcU6xdf3Plkv6tXry7WV6xYUay/9957HW/7cNbxOLvtB2zvtL1lzLLbbL9ne3P1c3mdzQKo30RO438h6dJxlv9LRMyrfn5Tb1sA6tY27BGxQdKuPvQCoIe6+YBuqe3XqtP841o9yfYS28O2W/8zMgA912nYfybpFEnzJI1IurvVEyNiKCLOjoizO9wWgBp0FPaI2BER+yPigKSfS5pfb1sA6tZR2G3PHPNwoaQtrZ4LYDC0HWe3vVbS9yUdL2mHpJ9Wj+dJCknvSvpxRLS9uJhx9sln2rRpxfqVV17ZstbuWnl73OHir6xfv75YX7BgQbE+WbUaZz9iAisuGmfx/V13BKCv+LoskARhB5Ig7EAShB1IgrADSXCJKxrzxRdfFOtHHFEeLNq3b1+xfskll7SsPf/888V1D2f8K2kgOcIOJEHYgSQIO5AEYQeSIOxAEoQdSKLtVW/I7ayzzirWr7vuumL9nHPOaVlrN47eztatW4v1DRs2dPX6kw1HdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgnH2SW7u3LnF+tKlS4v1a665plg/8cQTD7mnidq/f3+xPjJS/u/lBw4cqLOdwx5HdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgnH2w0C7sexFi8abaHdUu3H02bNnd9JSLYaHh4v1FStWFOvr1q2rs51Jr+2R3fZJtp+zvc32G7ZvqZZPt/2M7beq2+N63y6ATk3kNH6fpL+PiD+X9FeSbrZ9uqRbJT0bEadKerZ6DGBAtQ17RIxExKbq/h5J2yTNknSVpDXV09ZIurpHPQKowSG9Z7c9W9L3JG2UNCMiRqTRPwi2T2ixzhJJS7rsE0CXJhx229+W9Iikn0TEx/a4c8d9Q0QMSRqqXoOJHYGGTGjozfa3NBr0X0bEo9XiHbZnVvWZknb2pkUAdWh7ZPfoIfx+Sdsi4p4xpXWSbpC0srp9vCcdTgIzZswo1k8//fRi/d577y3WTzvttEPuqS4bN24s1u+8886WtccfL//KcIlqvSZyGn++pL+V9LrtzdWy5RoN+a9tL5b0e0k/7EmHAGrRNuwR8Z+SWr1Bv7jedgD0Cl+XBZIg7EAShB1IgrADSRB2IAkucZ2g6dOnt6ytXr26uO68efOK9Tlz5nTSUi1efPHFYv3uu+8u1p966qli/bPPPjvkntAbHNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IIk04+znnntusb5s2bJiff78+S1rs2bN6qinunz66acta6tWrSque8cddxTre/fu7agnDB6O7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQRJpx9oULF3ZV78bWrVuL9SeffLJY37dvX7FeuuZ89+7dxXWRB0d2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUjCEVF+gn2SpIcknSjpgKShiPhX27dJuknS/1ZPXR4Rv2nzWuWNAehaRIw76/JEwj5T0syI2GT7aEkvS7pa0t9I+iQi7ppoE4Qd6L1WYZ/I/Owjkkaq+3tsb5PU7L9mAXDIDuk9u+3Zkr4naWO1aKnt12w/YPu4FusssT1se7i7VgF0o+1p/FdPtL8t6QVJKyLiUdszJH0gKST9k0ZP9W9s8xqcxgM91vF7dkmy/S1JT0p6KiLuGac+W9KTEXFmm9ch7ECPtQp729N425Z0v6RtY4NefXB30EJJW7ptEkDvTOTT+Ask/Yek1zU69CZJyyUtkjRPo6fx70r6cfVhXum1OLIDPdbVaXxdCDvQex2fxgOYHAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ9HvK5g8k/c+Yx8dXywbRoPY2qH1J9NapOnv7s1aFvl7P/o2N28MRcXZjDRQMam+D2pdEb53qV2+cxgNJEHYgiabDPtTw9ksGtbdB7Uuit071pbdG37MD6J+mj+wA+oSwA0k0Enbbl9p+0/bbtm9toodWbL9r+3Xbm5uen66aQ2+n7S1jlk23/Yztt6rbcefYa6i322y/V+27zbYvb6i3k2w/Z3ub7Tds31Itb3TfFfrqy37r+3t221Mk/U7SAknbJb0kaVFEbO1rIy3YflfS2RHR+BcwbP+1pE8kPXRwai3b/yxpV0SsrP5QHhcR/zAgvd2mQ5zGu0e9tZpm/O/U4L6rc/rzTjRxZJ8v6e2IeCcivpT0K0lXNdDHwIuIDZJ2fW3xVZLWVPfXaPSXpe9a9DYQImIkIjZV9/dIOjjNeKP7rtBXXzQR9lmS/jDm8XYN1nzvIelp2y/bXtJ0M+OYcXCarer2hIb7+bq203j309emGR+YfdfJ9OfdaiLs401NM0jjf+dHxF9KukzSzdXpKibmZ5JO0egcgCOS7m6ymWqa8Uck/SQiPm6yl7HG6asv+62JsG+XdNKYx9+R9H4DfYwrIt6vbndKekyjbzsGyY6DM+hWtzsb7ucrEbEjIvZHxAFJP1eD+66aZvwRSb+MiEerxY3vu/H66td+ayLsL0k61fZ3bR8p6UeS1jXQxzfYnlp9cCLbUyX9QIM3FfU6STdU92+Q9HiDvfyRQZnGu9U042p43zU+/XlE9P1H0uUa/UT+vyX9YxM9tOhrjqRXq583mu5N0lqNntb9n0bPiBZL+lNJz0p6q7qdPkC9/ZtGp/Z+TaPBmtlQbxdo9K3ha5I2Vz+XN73vCn31Zb/xdVkgCb5BByRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ/D+f1mbt6t55/AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data[0][0][0], cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc91469",
   "metadata": {},
   "source": [
    "#Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6d44ad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lenet():\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(1, 6, 5, padding=2),\n",
    "        nn.ReLU(),\n",
    "        nn.AvgPool2d(2, stride=2),\n",
    "        nn.Conv2d(6, 16, 5, padding=0),\n",
    "        nn.ReLU(),\n",
    "        nn.AvgPool2d(2, stride=2),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(400, 120),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(120, 84),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(84, 10)\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8004a41",
   "metadata": {},
   "source": [
    "#Validating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fc97b5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, data):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i, (images, labels) in enumerate(data):\n",
    "        images = images.cuda()\n",
    "        x = model(images)\n",
    "        value, pred = torch.max(x,1)\n",
    "        pred = pred.data.cpu()\n",
    "        total += x.size(0)\n",
    "        correct += torch.sum(pred == labels)\n",
    "    return correct*100./total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c119a3",
   "metadata": {},
   "source": [
    "#Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "258aded4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(numb_epoch=3, lr=1e-3, device=\"cpu\"):\n",
    "    accuracies = []\n",
    "    cnn = create_lenet().to(device)\n",
    "    cec = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(cnn.parameters(), lr=lr)\n",
    "    max_accuracy = 0\n",
    "    for epoch in range(numb_epoch):\n",
    "        for i, (images, labels) in enumerate(train_dl):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred = cnn(images)\n",
    "            loss = cec(pred, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        accuracy = float(validate(cnn, val_dl))\n",
    "        accuracies.append(accuracy)\n",
    "        if accuracy > max_accuracy:\n",
    "            best_model = copy.deepcopy(cnn)\n",
    "            max_accuracy = accuracy\n",
    "            print(\"Saving Best Model with Accuracy: \", accuracy)\n",
    "        print('Epoch:', epoch+1, \"Accuracy :\", accuracy, '%')\n",
    "    plt.plot(accuracies)\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc6360a",
   "metadata": {},
   "source": [
    "#GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "98bcfbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Cuda Available\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"No Cuda Available\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544d4094",
   "metadata": {},
   "source": [
    "#Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9bc3cc61",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-f486916d7e9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlenet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-47-e20d6457c914>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(numb_epoch, lr, device)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0maccuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_accuracy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-b84940f21d08>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, data)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m     r\"\"\"Context-manager that changes the selected device.\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "lenet = train(40, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0252f2",
   "metadata": {},
   "source": [
    "#Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "246ad16e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lenet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-0a42111bb8d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlenet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lenet.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lenet' is not defined"
     ]
    }
   ],
   "source": [
    "torch.save(lenet.state_dict(), \"lenet.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f797da",
   "metadata": {},
   "source": [
    "#Optional: Loading the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f8f4d258",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'lenet.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-c44cedf39eb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlenet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_lenet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlenet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lenet.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlenet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    697\u001b[0m                     \u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<i'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                     \u001b[0;31m# skip next 4 bytes; legacy encoding treated ndim as 8 bytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                     \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'<{ndim}q'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'<{ndim}q'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_open_buffer_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'lenet.pth'"
     ]
    }
   ],
   "source": [
    "lenet = create_lenet().to(device)\n",
    "lenet.load_state_dict(torch.load(\"lenet.pth\"))\n",
    "lenet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "005fedf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the Function to test validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "161f726d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_dl(model, data):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for i, (images, labels) in enumerate(data):\n",
    "        images = images.cuda()\n",
    "        x = model(images)\n",
    "        value, pred = torch.max(x, 1)\n",
    "        pred = pred.data.cpu()\n",
    "        y_pred.extend(list(pred.numpy()))\n",
    "        y_true.extend(list(labels.numpy()))\n",
    "    return np.array(y_pred), np.array(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8ab02f5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-2c27efd7c7d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_dl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlenet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-54-1111731c7380>\u001b[0m in \u001b[0;36mpredict_dl\u001b[0;34m(model, data)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m     r\"\"\"Context-manager that changes the selected device.\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "y_pred, y_true = predict_dl(lenet, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "38118dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ac16f81a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-3306f58f78af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_true' is not defined"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_true, y_pred, labels=np.arange(0,10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e2fba230",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Inference function to get prediction for any given image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4feac38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(path, model, device):\n",
    "    r = requests.get(path)\n",
    "    with BytesIO(r.content) as f:\n",
    "        img = Image.open(f).convert(mode=\"L\")\n",
    "        img = img.resize((28, 28))\n",
    "        x = (255 - np.expand_dims(np.array(img), -1))/255.\n",
    "    with torch.no_grad():\n",
    "        pred = model(torch.unsqueeze(T(x), axis=0).float().to(device))\n",
    "        return F.softmax(pred, dim=-1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e9bb39ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the image from the web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0aa25af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"https://previews.123rf.com/images/aroas/aroas1704/aroas170400068/79321959-handwritten-sketch-black-number-8-on-white-background.jpg\"\n",
    "r = requests.get(path)\n",
    "with BytesIO(r.content) as f:\n",
    "    img = Image.open(f).convert(mode=\"L\")\n",
    "    img = img.resize((28, 28))\n",
    "x = (255 - np.expand_dims(np.array(img), -1))/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fe83c9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Showing the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "05c64f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f83b0ddd160>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x.squeeze(-1), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "117586ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a2ad67f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 8, Prob: 11.101661622524261 %\n"
     ]
    }
   ],
   "source": [
    "pred = inference(path, lenet, device=device)\n",
    "pred_idx = np.argmax(pred)\n",
    "print(f\"Predicted: {pred_idx}, Prob: {pred[0][pred_idx]*100} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "93b8c023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09277   , 0.09763285, 0.09156657, 0.10440112, 0.09876423,\n",
       "        0.0964259 , 0.100979  , 0.09674966, 0.11101662, 0.10969406]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b9e316",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
